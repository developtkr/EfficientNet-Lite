{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3143e33e-f40a-4088-a63c-85f0ead6fd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from efficientnet_lite import efficientnet_lite_params, build_efficientnet_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ae0fdf9-3226-4d28-87f0-f1ae7437b5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d001c34d-4121-46d3-acf0-ed0bfc504147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base64 인코딩 함수\n",
    "def imageToString(img):\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    img.save(img_byte_arr, format='PNG')\n",
    "    my_encoded_img = base64.encodebytes(img_byte_arr.getvalue()).decode('ascii')\n",
    "    return my_encoded_img\n",
    "\n",
    "# Base64 디코딩 및 이미지 변환 함수\n",
    "def stringToImage(base64_string, mode='RGBA'):\n",
    "    imgdata = base64.b64decode(str(base64_string))\n",
    "    img = Image.open(io.BytesIO(imgdata)).convert(mode)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a82b263-e815-4e90-b350-6e3e7f56b093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(net, checkpoint):\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    temp = OrderedDict()\n",
    "    if 'state_dict' in checkpoint:\n",
    "        checkpoint = dict(checkpoint['state_dict'])\n",
    "        # print(checkpoint)\n",
    "    for k in checkpoint:\n",
    "        # k2 = 'module.'+k if not k.startswith('module.') else k\n",
    "        k2 = k.replace('module.', '') if k.startswith('module.') else k\n",
    "        temp[k2] = checkpoint[k]\n",
    "\n",
    "    net.load_state_dict(temp, strict=True)\n",
    "\n",
    "def run_prediction(model, input_list):\n",
    "    pred_result = []\n",
    "    total_proc_time = 0.0\n",
    "    total_model_time = 0.0\n",
    "    for item in input_list:\n",
    "        proc_s_time = time.time()\n",
    "        # 이미지 불러오기\n",
    "        image = Image.open(item).convert('RGB')\n",
    "\n",
    "        # 전처리 수행\n",
    "        input_tensor = preprocess(image)\n",
    "        input_batch = input_tensor.unsqueeze(0)  # batch size = 1\n",
    "\n",
    "        model_s_time = time.time()\n",
    "        # 모델 추론\n",
    "        with torch.no_grad():\n",
    "            output = model(input_batch.to(device))\n",
    "        # 예측 결과 출력\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        model_r_time = time.time() - model_s_time\n",
    "        proc_r_time = time.time() - proc_s_time\n",
    "\n",
    "        total_proc_time += proc_r_time\n",
    "        total_model_time += model_r_time\n",
    "        pred_result.append(predicted.item())\n",
    "    # print('Predicted:', predicted.item(), '|', 'Time: ', r_time, output, predicted)\n",
    "    return {\n",
    "        'result': pred_result,\n",
    "        'n': len(pred_result),\n",
    "        'total_proc_time': total_proc_time,\n",
    "        'total_model_time': total_model_time,\n",
    "        'avg_proc_time': total_proc_time / len(pred_result),\n",
    "        'avg_model_time': total_model_time / len(pred_result),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8706fc29-0a3a-4b05-ab6a-813a7b1178ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 전처리 파이프라인\n",
    "input_size = 224\n",
    "CROP_PADDING = 32\n",
    "MEAN_RGB = [0.498, 0.498, 0.498]\n",
    "STDDEV_RGB = [0.502, 0.502, 0.502]\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(input_size + CROP_PADDING, interpolation=Image.BICUBIC),\n",
    "    transforms.CenterCrop(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN_RGB, STDDEV_RGB)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ce1087-65a4-4351-b3b2-e481120407ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# 모델 로딩 - 필수 파라미터\n",
    "use_gpu = False\n",
    "num_classes = 2\n",
    "model_name = 'efficientnet_lite0'\n",
    "device = torch.device(\"cuda\") if use_gpu else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# 모델 로딩\n",
    "ckpt_path = f\"./models/b64_lr5e-3_lite0/checkpoint-010000.pth.tar\"\n",
    "ckpt_selected = torch.load(ckpt_path, map_location=None if use_gpu else 'cpu')\n",
    "model = build_efficientnet_lite(model_name, num_classes)\n",
    "load_checkpoint(model, ckpt_selected)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1672c11-af35-4614-8536-2ba41c03bc0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 이미지 불러오기\n",
    "image = Image.open('../data/hair_verifying_all/positive/Female_O_L100.jpeg').convert('RGB')\n",
    "\n",
    "img_base64 = imageToString(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be3ec2e4-3863-49be-be8d-5b18945f2ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 | Time:  0.1043405532836914 [-4.4621453  4.449293 ] 1\n"
     ]
    }
   ],
   "source": [
    "# input이 base64라고 가정하고..\n",
    "img_input = stringToImage(img_base64).convert(\"RGB\")\n",
    "\n",
    "# 전처리 수행\n",
    "input_tensor = preprocess(img_input)\n",
    "input_batch = input_tensor.unsqueeze(0)  # batch size = 1\n",
    "\n",
    "s_time = time.time()\n",
    "# 모델 추론\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch.to(device))\n",
    "# 예측 결과 출력\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "r_time = time.time() - s_time\n",
    "print('Predicted:', predicted.item(), '|', 'Time: ', r_time, output.numpy()[0], predicted.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872cd50-f74f-4684-8d61-d295f60053f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
