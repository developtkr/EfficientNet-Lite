{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3143e33e-f40a-4088-a63c-85f0ead6fd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from efficientnet_lite import efficientnet_lite_params, build_efficientnet_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae0fdf9-3226-4d28-87f0-f1ae7437b5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a37fd72-d96d-400a-a858-6f46ace266fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(net, checkpoint):\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    temp = OrderedDict()\n",
    "    if 'state_dict' in checkpoint:\n",
    "        checkpoint = dict(checkpoint['state_dict'])\n",
    "        # print(checkpoint)\n",
    "    for k in checkpoint:\n",
    "        # k2 = 'module.'+k if not k.startswith('module.') else k\n",
    "        k2 = k.replace('module.', '') if k.startswith('module.') else k\n",
    "        temp[k2] = checkpoint[k]\n",
    "\n",
    "    net.load_state_dict(temp, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfae7a3a-1114-4e88-a0b9-b4b4f0238835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_prediction(model, input_list):\n",
    "    pred_result = []\n",
    "    total_proc_time = 0.0\n",
    "    total_model_time = 0.0\n",
    "    for item in input_list:\n",
    "        proc_s_time = time.time()\n",
    "        # 이미지 불러오기\n",
    "        image = Image.open(item).convert('RGB')\n",
    "\n",
    "        # 전처리 수행\n",
    "        input_tensor = preprocess(image)\n",
    "        input_batch = input_tensor.unsqueeze(0)  # batch size = 1\n",
    "\n",
    "        model_s_time = time.time()\n",
    "        # 모델 추론\n",
    "        with torch.no_grad():\n",
    "            output = model(input_batch.to(device))\n",
    "        # 예측 결과 출력\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        model_r_time = time.time() - model_s_time\n",
    "        proc_r_time = time.time() - proc_s_time\n",
    "\n",
    "        total_proc_time += proc_r_time\n",
    "        total_model_time += model_r_time\n",
    "        pred_result.append(predicted.item())\n",
    "    # print('Predicted:', predicted.item(), '|', 'Time: ', r_time, output, predicted)\n",
    "    return {\n",
    "        'result': pred_result,\n",
    "        'n': len(pred_result),\n",
    "        'total_proc_time': total_proc_time,\n",
    "        'total_model_time': total_model_time,\n",
    "        'avg_proc_time': total_proc_time / len(pred_result),\n",
    "        'avg_model_time': total_model_time / len(pred_result),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8706fc29-0a3a-4b05-ab6a-813a7b1178ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 전처리 파이프라인\n",
    "input_size = 224\n",
    "CROP_PADDING = 32\n",
    "MEAN_RGB = [0.498, 0.498, 0.498]\n",
    "STDDEV_RGB = [0.502, 0.502, 0.502]\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(input_size + CROP_PADDING, interpolation=Image.BICUBIC),\n",
    "    transforms.CenterCrop(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN_RGB, STDDEV_RGB)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f93711d-e6a4-4901-a1de-8aa61d623709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "use_gpu = False\n",
    "num_classes = 2\n",
    "model_name = 'efficientnet_lite0'\n",
    "device = torch.device(\"cuda\") if use_gpu else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "ckpt_path = f\"./models/b64_lr5e-3_lite0/checkpoint-010000.pth.tar\"\n",
    "ckpt_selected = torch.load(ckpt_path, map_location=None if use_gpu else 'cpu')\n",
    "model = build_efficientnet_lite(model_name, num_classes)\n",
    "load_checkpoint(model, ckpt_selected)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1594e44-9a95-453f-af34-2994bd521ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 | Time:  0.025983095169067383 [-4.4621453  4.449293 ] 1\n"
     ]
    }
   ],
   "source": [
    "# 이미지 불러오기\n",
    "image = Image.open('../data/hair_verifying_all/positive/Female_O_L100.jpeg').convert('RGB')\n",
    "\n",
    "# 전처리 수행\n",
    "input_tensor = preprocess(image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # batch size = 1\n",
    "\n",
    "s_time = time.time()\n",
    "# 모델 추론\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch.to(device))\n",
    "# 예측 결과 출력\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "r_time = time.time() - s_time\n",
    "print('Predicted:', predicted.item(), '|', 'Time: ', r_time, output.numpy()[0], predicted.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1672c11-af35-4614-8536-2ba41c03bc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ec2e4-3863-49be-be8d-5b18945f2ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872cd50-f74f-4684-8d61-d295f60053f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
